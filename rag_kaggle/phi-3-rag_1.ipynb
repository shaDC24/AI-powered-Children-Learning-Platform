{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"kernelVersion","sourceId":298661817}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"title","cell_type":"markdown","source":"# ЁЯза Phi-3 RAG тАФ Bengali Q&A + Quiz Generation\n### NCTB Class 3 AI Tutor | Group 11 тАФ BUET CSE\n\n**ржПржЗ notebook ржП ржпрж╛ рж╣ржмрзЗ:**\n1. ржЖржЧрзЗрж░ notebook ржПрж░ FAISS index load ржХрж░рж╛\n2. Phi-3 Mini model download ржУ load ржХрж░рж╛ (Kaggle T4 GPU рждрзЗ ржЪрж▓ржмрзЗ)\n3. Bengali/English ржкрзНрж░рж╢рзНржи тЖТ NCTB context retrieve тЖТ Phi-3 ржЙрждрзНрждрж░\n4. AI ржжрж┐ржпрж╝рзЗ Quiz generate ржХрж░рж╛\n5. Interactive chat loop test ржХрж░рж╛\n\n---\n**тЪая╕П Setup:**\n- ржЖржЧрзЗрж░ OCR notebook ржПрж░ output dataset рж╣рж┐рж╕рзЗржмрзЗ add ржХрж░рзЛ\n- GPU T4 x2 ON рж░рж╛ржЦрзЛ\n- Internet ON рж░рж╛ржЦрзЛ (model download ржПрж░ ржЬржирзНржп)","metadata":{}},{"id":"step1-md","cell_type":"markdown","source":"## Step 1: Install Libraries","metadata":{}},{"id":"b9bec460-e03a-4311-bb68-5766118d0310","cell_type":"code","source":"import subprocess\n# ржЖржЧрзЗрж░ OCR notebook ржПрж░ output copy ржХрж░рзЛ\nsubprocess.run(['cp', '-r', \n    '/kaggle/input/notebooks/sharbanichowdhury/nctb-class3-bengali-ocr', \n    '/kaggle/working/'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:22:37.900638Z","iopub.execute_input":"2026-02-19T12:22:37.900996Z","iopub.status.idle":"2026-02-19T12:22:38.357839Z","shell.execute_reply.started":"2026-02-19T12:22:37.900968Z","shell.execute_reply":"2026-02-19T12:22:38.356898Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"CompletedProcess(args=['cp', '-r', '/kaggle/input/notebooks/sharbanichowdhury/nctb-class3-bengali-ocr', '/kaggle/working/'], returncode=0)"},"metadata":{}}],"execution_count":13},{"id":"install","cell_type":"code","source":"!pip install -q transformers accelerate bitsandbytes\n!pip install -q sentence-transformers faiss-cpu\n!pip install -q langchain\n\nprint('тЬЕ рж╕ржм install рж╣ржпрж╝рзЗржЫрзЗ!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:22:38.359147Z","iopub.execute_input":"2026-02-19T12:22:38.359568Z","iopub.status.idle":"2026-02-19T12:22:50.488913Z","shell.execute_reply.started":"2026-02-19T12:22:38.359539Z","shell.execute_reply":"2026-02-19T12:22:50.487886Z"}},"outputs":[{"name":"stdout","text":"тЬЕ рж╕ржм install рж╣ржпрж╝рзЗржЫрзЗ!\n","output_type":"stream"}],"execution_count":14},{"id":"step2-md","cell_type":"markdown","source":"## Step 2: FAISS Index Load ржХрж░рж╛ (ржЖржЧрзЗрж░ notebook ржерзЗржХрзЗ)","metadata":{}},{"id":"load-index","cell_type":"code","source":"import os, pickle, json\nimport numpy as np\nimport faiss\nfrom sentence_transformers import SentenceTransformer\nimport torch\n\n# тФАтФА Paths тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФА\n# ржЖржЧрзЗрж░ notebook ржПрж░ output Kaggle Dataset рж╣рж┐рж╕рзЗржмрзЗ add ржХрж░рждрзЗ рж╣ржмрзЗ\n# Dataset name ржпржжрж┐ 'nctb-rag-output' рж╣ржпрж╝:\nBASE =  '/kaggle/input/notebooks/sharbanichowdhury/nctb-class3-bengali-ocr'  # тЖР рждрзЛржорж╛рж░ dataset name ржЕржирзБржпрж╛ржпрж╝рзА change ржХрж░рзЛ\n\n# Fallback: working directory рждрзЗ ржерж╛ржХрж▓рзЗ рж╕рзЗржЦрж╛ржи ржерзЗржХрзЗ ржирж╛ржУ\nif not os.path.exists(BASE):\n    # BASE = '/kaggle/working\n    BASE =  '/kaggle/working/'\n    print('тЪая╕П  Input dataset ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐ тАФ working directory ржерзЗржХрзЗ load рж╣ржЪрзНржЫрзЗ')\n\nFAISS_PATH  = f'{BASE}/faiss_index/bangla_class3.faiss'\nCHUNKS_PATH = f'{BASE}/faiss_index/chunks.pkl'\n\n# Load FAISS index\nprint('ЁЯФД FAISS index load рж╣ржЪрзНржЫрзЗ...')\nINDEX = faiss.read_index(FAISS_PATH)\n\n# Load text chunks\nwith open(CHUNKS_PATH, 'rb') as f:\n    CHUNKS = pickle.load(f)\n\nprint(f'тЬЕ Index loaded!')\nprint(f'   Vectors: {INDEX.ntotal}')\nprint(f'   Chunks: {len(CHUNKS)}')\nprint(f'   Sample chunk: {CHUNKS[5][:150]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:22:50.490563Z","iopub.execute_input":"2026-02-19T12:22:50.490909Z","iopub.status.idle":"2026-02-19T12:22:50.503278Z","shell.execute_reply.started":"2026-02-19T12:22:50.490875Z","shell.execute_reply":"2026-02-19T12:22:50.502344Z"}},"outputs":[{"name":"stdout","text":"ЁЯФД FAISS index load рж╣ржЪрзНржЫрзЗ...\nтЬЕ Index loaded!\n   Vectors: 190\n   Chunks: 190\n   Sample chunk: ред рж╕рж╛ржорж╛ржЬрж┐ржХ ржУ ржЕрж░рзНржержирзИрждрж┐ржХ рж╕рзНрждрж░ ржПржмржВ ржзрж░рзНржо-ржмрж░рзНржг ржХрж┐ржВржмрж╛ рж▓рзИржЩрзНржЧрж┐ржХ ржкрж░рж┐ржЪржпрж╝ ржХрзЛржирзЛ рж╢рж┐рж╢рзБрж░ рж╢рж┐ржХрзНрж╖рж╛ржЧрзНрж░рж╣ржгрзЗрж░ ржкржерзЗ ржпрж╛рждрзЗ ржмрж╛ржзрж╛ ржирж╛ рж╣ржпрж╝рзЗ ржжрж╛ржБржбрж╝рж╛ржпрж╝ ржП ржмрж┐рж╖ржпрж╝рзЗржУ ржмрж┐рж╢рзЗрж╖ ржжрзГрж╖рзНржЯрж┐ рж░рж╛ржЦрж╛ рж╣ржпрж╝рзЗ\n","output_type":"stream"}],"execution_count":15},{"id":"step3-md","cell_type":"markdown","source":"## Step 3: Embedding Model Load (Retrieval ржПрж░ ржЬржирзНржп)","metadata":{}},{"id":"embed-model","cell_type":"code","source":"print('ЁЯФД Embedding model load рж╣ржЪрзНржЫрзЗ...')\n\nEMBED_MODEL = SentenceTransformer(\n    'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n)\n\ndef retrieve(question, k=3):\n    \"\"\"Student ржПрж░ question ржПрж░ ржЬржирзНржп relevant NCTB chunks ржЦрзБржБржЬрзЗ ржЖржирж╛ред\"\"\"\n    q_emb = EMBED_MODEL.encode(\n        [question],\n        normalize_embeddings=True,\n        convert_to_numpy=True\n    ).astype('float32')\n    \n    scores, indices = INDEX.search(q_emb, k)\n    \n    results = []\n    for score, idx in zip(scores[0], indices[0]):\n        if idx >= 0:\n            results.append({\n                'text': CHUNKS[idx],\n                'score': float(score)\n            })\n    return results\n\n# Quick test\ntest = retrieve('ржмржирзНржзрзБ ржХрж╛ржХрзЗ ржмрж▓рзЗ?')\nprint(f'\\nтЬЕ Retrieval test:')\nfor i, r in enumerate(test, 1):\n    print(f'  [{i}] score={r[\"score\"]:.3f}: {r[\"text\"][:120]}...')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:22:50.504481Z","iopub.execute_input":"2026-02-19T12:22:50.504859Z","iopub.status.idle":"2026-02-19T12:22:56.485001Z","shell.execute_reply.started":"2026-02-19T12:22:50.504781Z","shell.execute_reply":"2026-02-19T12:22:56.484160Z"}},"outputs":[{"name":"stdout","text":"ЁЯФД Embedding model load рж╣ржЪрзНржЫрзЗ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97ad4fc4489e457d8b4738ef6401d24f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d387ef438374ab2beb2e5d67912dc67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad29f0e4479e47e5a9ed67de022207c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cedc5cfe12334e929e59ad7554aeb464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01ba8479614c44a39addc0fccd237828"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e919b65bf3964cb7adc5dccc71336a76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0e654dab1f542ae9c6da256bbd0df5f"}},"metadata":{}},{"name":"stderr","text":"\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\nKey                     | Status     |  | \n------------------------+------------+--+-\nembeddings.position_ids | UNEXPECTED |  | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/526 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5be2b42e8ca64a22824dfa01e7b32c84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a084fef98446b194fa9439de00701a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0324a9b9941c4997a3fc474523880ac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e46b67fc3f4696af1f195473ae54be"}},"metadata":{}},{"name":"stdout","text":"\nтЬЕ Retrieval test:\n  [1] score=0.547: ржЬрж┐ржЬрзНржЮрзЗрж╕ ржХрж░рж▓рзЗржи рждрзБржорж┐ ржХрзА ржХрж░ржмрзЗ? рж░рж╛рж╢рзЗржж ржмрж▓рж▓ ? ржЕржЩрзНржХ ржжрзМржбрж╝ ржУ ржорзЛрж░ржЧ рж▓ржбрж╝рж╛ржЗ ржХрж░ржм ржХрзНрж▓рж╛рж╕рзЗрж░ рж╕ржмрж╛ржЗ ржнрж╛ржмржЫрж┐рж▓ , рж░рж╛рж╢рзЗржж ржкрж╛рж░ржмрзЗ рждрзЛ ! ржирзЛржорж╛ржи рж╕рзНржпрж╛рж░ ржмрж▓...\n  [2] score=0.520: ржПржмрж╛рж░ ржПржХржЯрж╛ ржЫржХ ржЖржБржХрж┐ | ржЫржХржЯрж┐рждрзЗ ржирж┐ржЬрзЗрж░ ржнрж╛рж▓рзЛ рж▓рж╛ржЧрж╛рж░ ржХржерж╛ рж▓рж┐ржЦрж┐ рж╕рзНржпрж╛рж░ ржмрзЛрж░рзНржбрзЗ ржПржХржЯрж┐ ржЫржХ ржЖржБржХрж▓рзЗржи ржмрж▓рж▓рзЗржи , ржЖржорж╛рж░ ржорждрзЛ ржХрж░рзЗ рждрзЛржорж░рж╛ржУ ржЫржХржЯрж┐ ржЖржБржХрзЛ...\n  [3] score=0.519: (ржШржи ржоржи)\nржкржбрж╝рж┐ ржЫрзБржЯрж┐рж░ ржжрж┐ржи ! ржШрзБржорж╛ржЪрзНржЫрж┐рж▓рж╛ржо | рж╣ржарж╛рзО рж╢рзБржирж┐ ржорж┐ржЙ ржорж┐ржЙ рж╢ржмрзНржж ржЬрзЗржЧрзЗ ржЙржарзЗ ржжрзЗржЦрж┐ ржШрж░рзЗрж░ ржнрзЗрждрж░ ржЫрзЛржЯрзНржЯ ржПржХржЯрж╛ ржмрж┐ржбрж╝рж╛рж▓ржЫрж╛ржирж╛ / ржЖржорж┐ ржЬрж┐ржЬрзНржЮрзЗ...\n","output_type":"stream"}],"execution_count":16},{"id":"step4-md","cell_type":"markdown","source":"## Step 4: Phi-3 Mini Load ржХрж░рж╛\n\n**Phi-3 Mini (3.8B)** тАФ Microsoft ржПрж░ lightweight modelред  \nKaggle T4 GPU рждрзЗ 4-bit quantization ржжрж┐ржпрж╝рзЗ ржЪрж▓ржмрзЗ (~4GB VRAM)ред","metadata":{}},{"id":"phi3-load","cell_type":"code","source":"# Hugging Face cache рж╕ржорзНржкрзВрж░рзНржг clear ржХрж░рзЛ\nimport shutil, os\n\nhf_cache = os.path.expanduser('~/.cache/huggingface')\nshutil.rmtree(hf_cache, ignore_errors=True)\nprint('тЬЕ Cache cleared!')\n\n# ржПржмрж╛рж░ Phi-3.5 use ржХрж░рзЛ тАФ Phi-3 ржПрж░ updated version, same size\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport torch\n\nMODEL_ID = 'microsoft/Phi-3.5-mini-instruct'  # Phi-3 тЖТ Phi-3.5 (bug fixed)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type='nf4'\n)\n\nTOKENIZER = AutoTokenizer.from_pretrained(MODEL_ID)\n\nprint('ЁЯФД Phi-3.5 Mini load рж╣ржЪрзНржЫрзЗ (~5 min)...')\nPHI3 = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    quantization_config=bnb_config,\n    device_map='auto',\n    torch_dtype=torch.float16,\n)\n\nPHI3.eval()\nprint(f'тЬЕ Ready! Memory: {torch.cuda.memory_allocated()//1024**2} MB')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:22:56.486048Z","iopub.execute_input":"2026-02-19T12:22:56.486419Z","iopub.status.idle":"2026-02-19T12:23:30.422509Z","shell.execute_reply.started":"2026-02-19T12:22:56.486390Z","shell.execute_reply":"2026-02-19T12:23:30.421532Z"}},"outputs":[{"name":"stdout","text":"тЬЕ Cache cleared!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83e0175045354c7eb63392c1ccebc970"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b311591ed61f48c0a7916ad2748725e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3db464acf22941be8d4afe309c5e7048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca12e11069e44f782df8a94d13fbee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6458223975d546f99b9800cd9bcda24e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80dda6cfd9ad48929e7b071ce1351a60"}},"metadata":{}},{"name":"stdout","text":"ЁЯФД Phi-3.5 Mini load рж╣ржЪрзНржЫрзЗ (~5 min)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ac43df27e9421c83a5343ce5929e60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (incomplete total...): 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85de8c17b4fd41d280bb539f0c3c5221"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c70b63f9ceb454a9fdbae48e55a5896"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/195 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e4983cff69c45d79aaae8841ee4de65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24190f351e5f42a09c2d091445e9fd3c"}},"metadata":{}},{"name":"stdout","text":"тЬЕ Ready! Memory: 2959 MB\n","output_type":"stream"}],"execution_count":17},{"id":"step5-md","cell_type":"markdown","source":"## Step 5: RAG Generation Function","metadata":{}},{"id":"rag-generate","cell_type":"code","source":"def generate_answer(question, mode='chat', max_new_tokens=300):\n    \"\"\"\n    Student ржПрж░ question ржПрж░ ржЬржирзНржп NCTB-grounded ржЙрждрзНрждрж░ generate ржХрж░рж╛ред\n    \n    mode:\n      'chat' тЖТ рж╕рж╣ржЬ Bengali ржЙрждрзНрждрж░\n      'quiz' тЖТ MCQ questions JSON format ржП\n      'explain' тЖТ ржмрж┐рж╕рзНрждрж╛рж░рж┐ржд ржмрзНржпрж╛ржЦрзНржпрж╛\n    \"\"\"\n    # Step 1: Relevant context retrieve ржХрж░рзЛ\n    chunks = retrieve(question, k=3)\n    context = '\\n\\n'.join(\n        f'[ржЕржВрж╢ {i+1}]: {c[\"text\"]}'\n        for i, c in enumerate(chunks)\n    )\n    \n    # Step 2: Mode ржЕржирзБржпрж╛ржпрж╝рзА prompt рждрзИрж░рж┐\n    if mode == 'chat':\n        system = (\n            'рждрзБржорж┐ ржПржХржЯрж┐ AI рж╢рж┐ржХрзНрж╖ржХред ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ рждрзГрждрзАржпрж╝ рж╢рзНрж░рзЗржгрж┐рж░ ржЫрж╛рждрзНрж░ржЫрж╛рждрзНрж░рзАржжрзЗрж░ '\n            'NCTB ржкрж╛ржарзНржпржмржЗ ржЕржирзБржпрж╛ржпрж╝рзА рж╕рж╛рж╣рж╛ржпрзНржп ржХрж░рзЛред '\n            'рж╕рж╣ржЬ, ржмржирзНржзрзБрждрзНржмржкрзВрж░рзНржг ржмрж╛ржВрж▓рж╛ржпрж╝ ржЫрзЛржЯ ржЙрждрзНрждрж░ ржжрж╛ржУред '\n            'рж╢рзБржзрзБ ржирж┐ржЪрзЗрж░ ржмржЗржпрж╝рзЗрж░ ржЕржВрж╢ ржерзЗржХрзЗ ржЙрждрзНрждрж░ ржжрж╛ржУред'\n        )\n        user = f'ржкрж╛ржарзНржпржмржЗржпрж╝рзЗрж░ ржЕржВрж╢:\\n{context}\\n\\nржкрзНрж░рж╢рзНржи: {question}'\n\n    elif mode == 'quiz':\n        system = (\n            'рждрзБржорж┐ ржПржХржЬржи рж╢рж┐ржХрзНрж╖ржХред NCTB ржкрж╛ржарзНржпржмржЗржпрж╝рзЗрж░ рждржерзНржп ржерзЗржХрзЗ '\n            'рждрзГрждрзАржпрж╝ рж╢рзНрж░рзЗржгрж┐рж░ ржЫрж╛рждрзНрж░ржжрзЗрж░ ржЬржирзНржп MCQ рждрзИрж░рж┐ ржХрж░рзЛред '\n            'рж╢рзБржзрзБ JSON format ржП output ржжрж╛ржУ, ржЕржирзНржп ржХрж┐ржЫрзБ рж▓рж┐ржЦржмрзЗ ржирж╛ред'\n        )\n        user = (\n            f'ржкрж╛ржарзНржпржмржЗржпрж╝рзЗрж░ ржЕржВрж╢:\\n{context}\\n\\n'\n            f'\"{question}\" ржмрж┐рж╖ржпрж╝рзЗ рзйржЯрж┐ рж╕рж╣ржЬ MCQ рждрзИрж░рж┐ ржХрж░рзЛред\\n'\n            'Format:\\n'\n            '{\"questions\": [{\"question\": \"...\", '\n            '\"options\": [\"ржХ) ...\", \"ржЦ) ...\", \"ржЧ) ...\", \"ржШ) ...\"], '\n            '\"correct\": \"ржХ\", \"explanation\": \"...\"}]}'\n        )\n\n    elif mode == 'explain':\n        system = (\n            'рждрзБржорж┐ ржПржХржЯрж┐ AI рж╢рж┐ржХрзНрж╖ржХред NCTB ржкрж╛ржарзНржпржмржЗ ржЕржирзБржпрж╛ржпрж╝рзА '\n            'рждрзГрждрзАржпрж╝ рж╢рзНрж░рзЗржгрж┐рж░ ржЫрж╛рждрзНрж░ржжрзЗрж░ ржЬржирзНржп ржмрж┐рж╖ржпрж╝ржЯрж┐ рж╕рж╣ржЬржнрж╛ржмрзЗ ржмрзНржпрж╛ржЦрзНржпрж╛ ржХрж░рзЛред '\n            'ржЙржжрж╛рж╣рж░ржг ржжрж┐ржпрж╝рзЗ ржмрзЛржЭрж╛ржУред'\n        )\n        user = f'ржкрж╛ржарзНржпржмржЗржпрж╝рзЗрж░ ржЕржВрж╢:\\n{context}\\n\\nржмрзНржпрж╛ржЦрзНржпрж╛ ржХрж░рзЛ: {question}'\n\n    # Step 3: Phi-3 format ржП prompt рждрзИрж░рж┐\n    messages = [\n        {'role': 'system', 'content': system},\n        {'role': 'user',   'content': user}\n    ]\n    \n    prompt = TOKENIZER.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    \n    # Step 4: Tokenize\n    inputs = TOKENIZER(\n        prompt,\n        return_tensors='pt',\n        truncation=True,\n        max_length=2048\n    ).to(PHI3.device)\n    \n    # Step 5: Generate\n    with torch.no_grad():\n        output = PHI3.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.3,     # Low temp = more focused/accurate\n            top_p=0.9,\n            repetition_penalty=1.1,\n            pad_token_id=TOKENIZER.eos_token_id\n        )\n    \n    # Step 6: Decode тАФ рж╢рзБржзрзБ ржирждрзБржи generated text\n    generated = output[0][inputs['input_ids'].shape[1]:]\n    answer = TOKENIZER.decode(generated, skip_special_tokens=True).strip()\n    \n    return answer, context  # context ржУ return ржХрж░рж┐ debug ржПрж░ ржЬржирзНржп\n\n\nprint('тЬЕ RAG generation function ready!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:23:30.424070Z","iopub.execute_input":"2026-02-19T12:23:30.424477Z","iopub.status.idle":"2026-02-19T12:23:30.442949Z","shell.execute_reply.started":"2026-02-19T12:23:30.424431Z","shell.execute_reply":"2026-02-19T12:23:30.441896Z"}},"outputs":[{"name":"stdout","text":"тЬЕ RAG generation function ready!\n","output_type":"stream"}],"execution_count":18},{"id":"step6-md","cell_type":"markdown","source":"## Step 6: Bengali Q&A Test","metadata":{}},{"id":"qa-test","cell_type":"code","source":"# Test questions тАФ Class 3 ржмрж╛ржВрж▓рж╛ ржмржЗ ржерзЗржХрзЗ\ntest_questions = [\n    'рждрзЛржорж╛рж░ ржмржирзНржзрзБ ржХрзЗ?',\n    'ржкрж░рж┐ржмрж╛рж░рзЗ ржХрж╛рж░рж╛ ржерж╛ржХрзЗ?',\n    'ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ ржХржерж╛ ржмрж▓рзЛред',\n    'What is this lesson about?',  # English test\n]\n\nprint('=' * 60)\nprint('ЁЯзк Bengali Q&A Test тАФ Phi-3 + NCTB RAG')\nprint('=' * 60)\n\nfor q in test_questions:\n    print(f'\\nтЭУ ржкрзНрж░рж╢рзНржи: {q}')\n    print('ЁЯдФ ржЙрждрзНрждрж░ generate рж╣ржЪрзНржЫрзЗ...')\n    \n    answer, ctx = generate_answer(q, mode='chat')\n    \n    print(f'ЁЯдЦ AI ржЙрждрзНрждрж░:\\n{answer}')\n    print(f'\\nЁЯУЪ Retrieved context (ржкрзНрж░ржержо рззрзжрзж chars): {ctx[:100]}...')\n    print('-' * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:23:30.444174Z","iopub.execute_input":"2026-02-19T12:23:30.444553Z","iopub.status.idle":"2026-02-19T12:24:28.833197Z","shell.execute_reply.started":"2026-02-19T12:23:30.444503Z","shell.execute_reply":"2026-02-19T12:24:28.832458Z"}},"outputs":[{"name":"stdout","text":"============================================================\nЁЯзк Bengali Q&A Test тАФ Phi-3 + NCTB RAG\n============================================================\n\nтЭУ ржкрзНрж░рж╢рзНржи: рждрзЛржорж╛рж░ ржмржирзНржзрзБ ржХрзЗ?\nЁЯдФ ржЙрждрзНрждрж░ generate рж╣ржЪрзНржЫрзЗ...\nЁЯдЦ AI ржЙрждрзНрждрж░:\nрж░рж╛рж╢рзЗржж\n\nЁЯУЪ Retrieved context (ржкрзНрж░ржержо рззрзжрзж chars): [ржЕржВрж╢ 1]: ржЬрж┐ржЬрзНржЮрзЗрж╕ ржХрж░рж▓рзЗржи рждрзБржорж┐ ржХрзА ржХрж░ржмрзЗ? рж░рж╛рж╢рзЗржж ржмрж▓рж▓ ? ржЕржЩрзНржХ ржжрзМржбрж╝ ржУ ржорзЛрж░ржЧ рж▓ржбрж╝рж╛ржЗ ржХрж░ржм ржХрзНрж▓рж╛рж╕рзЗрж░ рж╕ржмрж╛ржЗ ржнрж╛ржмржЫрж┐рж▓ , рж░рж╛...\n------------------------------------------------------------\n\nтЭУ ржкрзНрж░рж╢рзНржи: ржкрж░рж┐ржмрж╛рж░рзЗ ржХрж╛рж░рж╛ ржерж╛ржХрзЗ?\nЁЯдФ ржЙрждрзНрждрж░ generate рж╣ржЪрзНржЫрзЗ...\nЁЯдЦ AI ржЙрждрзНрждрж░:\nржкрж╛ржа ржХрзА ржХрж░ржм ржЖрж░ ржкрж╛ржБржЫрзЗржи\n\nржкрж╛ржа рззрзн ржерж╛ржХрзЗ,\n\nржкрзГрж╖рзНржарж╛ 106 \n\nржкрж╛ржа ржЖрж░ ржкрж╛ржБржЫрзЗржи\n\nржкрж░рж┐ржмрж╛рж░рзЗ ржХрж╛рж░рж╛ ржерж╛ржХрзЗ!\n\nЁЯУЪ Retrieved context (ржкрзНрж░ржержо рззрзжрзж chars): [ржЕржВрж╢ 1]: ржЬрж┐ржЬрзНржЮрзЗрж╕ ржХрж░рж▓рзЗржи рждрзБржорж┐ ржХрзА ржХрж░ржмрзЗ? рж░рж╛рж╢рзЗржж ржмрж▓рж▓ ? ржЕржЩрзНржХ ржжрзМржбрж╝ ржУ ржорзЛрж░ржЧ рж▓ржбрж╝рж╛ржЗ ржХрж░ржм ржХрзНрж▓рж╛рж╕рзЗрж░ рж╕ржмрж╛ржЗ ржнрж╛ржмржЫрж┐рж▓ , рж░рж╛...\n------------------------------------------------------------\n\nтЭУ ржкрзНрж░рж╢рзНржи: ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ ржХржерж╛ ржмрж▓рзЛред\nЁЯдФ ржЙрждрзНрждрж░ generate рж╣ржЪрзНржЫрзЗ...\nЁЯдЦ AI ржЙрждрзНрждрж░:\nржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ ржЫрзЛржЯ ржЙрждрзНрждрж░:\n\nржкрзНрж░ржлрзЗрж╕рж░ рж░ржмрж┐ржЙрж▓ ржХржмрзАрж░ ржЪрзМржзрзБрж░рзА ржЪрзЗржпрж╝рж╛рж░ржорзНржпрж╛ржи, ржЬрж╛рждрзАржпрж╝ рж╢рж┐ржХрзНрж╖рж╛ржХрзНрж░ржо ржУ ржкрж╛ржарзНржпржкрзБрж╕рзНрждржХ ржмрзЛрж░рзНржб, ржЖржЬрж┐ржХрж╛рж░ рж╢рж┐рж╢рзБ рж╕рзБржлрж┐ржпрж╝рж╛ ржХрж╛ржорж╛рж▓\n\n(рж╕)-ржХрзЗ рж╣рждрзНржпрж╛ ржХрж░рж╛рж░ ржШрзЛрж╖ржгрж╛ ржжрзЗржпрж╝ рждржЦржи ржорзБрж╣рж╛ржорзНржоржж (рж╕) ржоржХрзНржХрж╛ ржерзЗржХрзЗ рж╣рж┐ржЬрж░ржд ржХрж░рзЗржи, ржЖржмрзБ ржмржХрж░ (рж░рж╛)\n\nржкрж╛ржа рззрзп, C_r -- _$[4_\n\nЁЯУЪ Retrieved context (ржкрзНрж░ржержо рззрзжрзж chars): [ржЕржВрж╢ 1]: рж╕рзЗржкрзНржЯрзЗржорзНржмрж░ рзирзжрзирзл\nржкрзНрж░ржлрзЗрж╕рж░ рж░ржмрж┐ржЙрж▓ ржХржмрзАрж░ ржЪрзМржзрзБрж░рзА ржЪрзЗржпрж╝рж╛рж░ржорзНржпрж╛ржи (ржЕрждрж┐рж░рж┐ржХрзНржд ржжрж╛ржпрж╝рж┐рждрзНржм)\nржЬрж╛рждрзАржпрж╝ рж╢рж┐ржХрзНрж╖рж╛ржХрзНрж░ржо...\n------------------------------------------------------------\n\nтЭУ ржкрзНрж░рж╢рзНржи: What is this lesson about?\nЁЯдФ ржЙрждрзНрждрж░ generate рж╣ржЪрзНржЫрзЗ...\nЁЯдЦ AI ржЙрждрзНрждрж░:\nржПржЗ рж╢ржмрзНржжржЧрзБрж▓рж┐ржд рж╢рж┐ржХрзНрж╖рж╛ рж╢ Bengali рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╢рж┐ржХрзНрж╖рж╛\n\nЁЯУЪ Retrieved context (ржкрзНрж░ржержо рззрзжрзж chars): [ржЕржВрж╢ 1]: рж╣ржпрж╝рзЗржЫрзЗ | ржПрж░ ржорж╛ржзрзНржпржорзЗ рж╢рж┐ржХрзНрж╖рж╛ржХрзЗ ржЕржзрж┐ржХрждрж░ ржЬрзАржмржиржорзБржЦрзА ржУ ржлрж▓ржкрзНрж░рж╕рзВ ржХрж░рж╛рж░ ржкрзНрж░ржпрж╝рж╛рж╕ ржмрж╛рж╕рзНрждржм ржнрж┐рждрзНрждрж┐ ржкрзЗржпрж╝рзЗржЫрзЗ |...\n------------------------------------------------------------\n","output_type":"stream"}],"execution_count":19},{"id":"step7-md","cell_type":"markdown","source":"## Step 7: Quiz Generation Test","metadata":{}},{"id":"quiz-test","cell_type":"code","source":"import json as json_lib\nimport re\n\ndef generate_quiz(topic, num_q=3):\n    \"\"\"Topic ржПрж░ ржЙржкрж░ MCQ quiz generate ржХрж░рж╛ред\"\"\"\n    answer, _ = generate_answer(topic, mode='quiz', max_new_tokens=500)\n    \n    # JSON parse ржХрж░рж╛рж░ ржЪрзЗрж╖рзНржЯрж╛\n    try:\n        # JSON block extract ржХрж░рзЛ\n        json_match = re.search(r'\\{.*\\}', answer, re.DOTALL)\n        if json_match:\n            quiz_data = json_lib.loads(json_match.group())\n            return quiz_data\n    except:\n        pass\n    \n    # JSON parse ржирж╛ рж╣рж▓рзЗ raw text return ржХрж░рзЛ\n    return {'raw': answer}\n\n\ndef display_quiz(quiz_data):\n    \"\"\"Quiz рж╕рзБржирзНржжрж░ржнрж╛ржмрзЗ display ржХрж░рж╛ред\"\"\"\n    if 'raw' in quiz_data:\n        print(quiz_data['raw'])\n        return\n    \n    questions = quiz_data.get('questions', [])\n    for i, q in enumerate(questions, 1):\n        print(f'\\n{i}. {q.get(\"question\", \"\")}')\n        for opt in q.get('options', []):\n            print(f'   {opt}')\n        print(f'   тЬЕ рж╕ржарж┐ржХ ржЙрждрзНрждрж░: {q.get(\"correct\", \"\")}')\n        if q.get('explanation'):\n            print(f'   ЁЯТб ржмрзНржпрж╛ржЦрзНржпрж╛: {q[\"explanation\"]}')\n\n\n# Test\nprint('=' * 60)\nprint('ЁЯУЭ Quiz Generation Test')\nprint('=' * 60)\n\ntopics = ['ржмржирзНржзрзБрждрзНржм', 'ржкрж░рж┐ржмрж╛рж░']\n\nfor topic in topics:\n    print(f'\\nЁЯОп Topic: {topic}')\n    print('Quiz generate рж╣ржЪрзНржЫрзЗ...')\n    quiz = generate_quiz(topic)\n    display_quiz(quiz)\n    print('-' * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:24:28.834139Z","iopub.execute_input":"2026-02-19T12:24:28.834406Z","iopub.status.idle":"2026-02-19T12:25:33.237585Z","shell.execute_reply.started":"2026-02-19T12:24:28.834381Z","shell.execute_reply":"2026-02-19T12:25:33.236736Z"}},"outputs":[{"name":"stdout","text":"============================================================\nЁЯУЭ Quiz Generation Test\n============================================================\n\nЁЯОп Topic: ржмржирзНржзрзБрждрзНржм\nQuiz generate рж╣ржЪрзНржЫрзЗ...\n{\n  \"questions\": [\n    {\n      \"question\": \"ржЖржиржирзНржжрзЗрж░ ржжрж┐ржи ржЖржорж╛рж░ ржкрж╛ржарзЗрж░ ржЕржВрж╢ ржЕржнрж╛ржЧрзЗ ржХржд ржкрзГрж╖рзНржарж╛ ржкрж░рзНржпрж╛рж▓ржи рж╣ржпрж╝?\",\n      \"options\": [\"ржХ) 41\", \"ржЦ) 35\", \"ржЧ) 30\", \"ржШ) 45\"],\n      \"correct\": \"ржХ) 41\",\n      \"explan_tion\": \"ржЖржиржирзНржжрзЗрж░ ржжрж┐ржи ржЙржжржпotted ржкрж╛ржарзЗрж░ ржЕржВрж╢рзЗ ржкрзГрж╖рзНржарж╛ 41 ржкрж░рзНржпрж╛рж▓ржи рж╣ржпрж╝.\"\n    },\n    {\n      \"question\": \"ржПржмрж╛рж░ ржПржХржЯрж╛ ржЫржХ ржЖржБржХрж▓рзЗржи 'ржирж┐ржЬрзЗрж░ ржнрж╛рж▓рзЛ рж▓рж╛ржЧрж╛рж░ ржХржерж╛' ржЪрж╛рж░рзНржирж┐рж╢ ржХрж░рзЗржи, ржПржЦржирзЛрж░ ржЫрж╛рждрзНрж░ ржХржд ржкрзГрж╖рзНржарж╛ рж╣ржпрж╝?\",\n      \"options\": [\"ржХ) 41\", \"ржЦ) 35\", \"ржЧ) 38\", \"ржШ) 40\"],\n      \"correct\": \"ржХ) 41\",\n      \"explan_tion\": \"ржПржмрж╛рж░ ржПржХржЯрж╛ ржЫржХ ржЖржБржХрж▓рзЗржи 'ржирж┐ржЬрзЗрж░ ржнрж╛рж▓рзЛ рж▓рж╛ржЧрж╛рж░ ржХржерж╛' ржЪрж╛рж░рзНржирж┐рж╢ ржХрж░рзЗржи, ржПржЦржирзЛрж░ ржЫрж╛рждрзНрж░ ржкрзГрж╖рзНя┐╜\n------------------------------------------------------------\n\nЁЯОп Topic: ржкрж░рж┐ржмрж╛рж░\nQuiz generate рж╣ржЪрзНржЫрзЗ...\n\n1. ржкрж╛ржарзНржпржмржЗржпрж╝рзЗрж░ ржкрж░рж┐ржмрж╛рж░ 'ржкрзГрж╖рзНржарж╛' ржЕржВрж╢рзЗрж░ ржкрж░рж┐ржорж╛ржирж┐ржд ржкрж░рж┐рж╢Mapping ржХрж┐?\n   ржХ) ржкрзГрж╖рзНржарж╛ 8\n   ржЦ) ржкрзГрж╖рзНржарж╛ 35\n   ржЧ) ржкрзГрж╖рзНржарж╛ 106\n   ржШ) ржкрж╛ржа\n   тЬЕ рж╕ржарж┐ржХ ржЙрждрзНрждрж░: ржЧ\n   ЁЯТб ржмрзНржпрж╛ржЦрзНржпрж╛: ржкрж░рж┐ржмрж╛рж░ 'ржкрзГрж╖рзНржарж╛' ржЕржВрж╢рзЗрж░ ржкрж░рж┐ржорж╛ржирж┐ржд ржкрж░рж┐рж╢Mapping рж╣рж▓ 'ржкрзГрж╖рзНржарж╛ 106', ржПрж░halbonoon ржЖржорж┐ 'ржкрзГрж╖рзНржарж╛ 35' ржЕржВрж╢рзЗрж░ ржкрж░рж┐рж╢Mapping ржмрж▓рж┐рждрзЗржЗ ржкрж░рж┐ржмрж╛рж░ рж╣рждрзЗржЗ ржнрж╛рж▓рзЛ ржирж╛ржЪрж┐рж▓рзЗржиред\n------------------------------------------------------------\n","output_type":"stream"}],"execution_count":20},{"id":"step8-md","cell_type":"markdown","source":"## Step 8: Interactive Chat Loop (Full Pipeline Test)","metadata":{}},{"id":"chat-loop","cell_type":"code","source":"def detect_language(text):\n    \"\"\"Bengali ржирж╛ржХрж┐ English рж╕рзЗржЯрж╛ detect ржХрж░рж╛ред\"\"\"\n    bn_chars = sum(1 for c in text if '\\u0980' <= c <= '\\u09FF')\n    return 'bengali' if bn_chars > len(text) * 0.2 else 'english'\n\ndef ai_tutor_response(student_input, conversation_history=[]):\n    \"\"\"\n    Full AI tutor pipeline:\n    Student input тЖТ Language detect тЖТ RAG тЖТ Phi-3 тЖТ Response\n    \"\"\"\n    lang = detect_language(student_input)\n    \n    # Quiz request detect ржХрж░рж╛\n    quiz_keywords = ['quiz', 'ржкрзНрж░рж╢рзНржи ржХрж░рзЛ', 'ржкрж░рзАржХрзНрж╖рж╛', 'mcq', 'ржХрзБржЗржЬ']\n    is_quiz = any(kw in student_input.lower() for kw in quiz_keywords)\n    \n    if is_quiz:\n        # Topic extract ржХрж░рзЛ ржПржмржВ quiz generate ржХрж░рзЛ\n        topic = student_input.replace('quiz', '').replace('ржХрзБржЗржЬ', '').replace('ржкрзНрж░рж╢рзНржи ржХрж░рзЛ', '').strip()\n        if not topic:\n            topic = 'ржмрж╛ржВрж▓рж╛ ржкрж╛ржа'\n        answer, ctx = generate_answer(topic, mode='quiz', max_new_tokens=500)\n    else:\n        answer, ctx = generate_answer(student_input, mode='chat')\n    \n    return {\n        'answer': answer,\n        'language': lang,\n        'mode': 'quiz' if is_quiz else 'chat',\n        'context_used': ctx[:200] + '...'\n    }\n\n\n# Simulate a conversation\nprint('=' * 60)\nprint('ЁЯТм AI Tutor тАФ Simulated Conversation')\nprint('=' * 60)\n\nconversations = [\n    'ржЖржорж╛ржХрзЗ ржмржирзНржзрзБрждрзНржм рж╕ржорзНржкрж░рзНржХрзЗ ржмрж▓рзЛред',\n    'ржмржирзНржзрзБрждрзНржм ржирж┐ржпрж╝рзЗ ржХрзБржЗржЬ ржжрж╛ржУред',\n    'Tell me about family.',\n]\n\nfor msg in conversations:\n    print(f'\\nЁЯСж Student: {msg}')\n    response = ai_tutor_response(msg)\n    print(f'ЁЯдЦ AI Tutor ({response[\"mode\"]} | {response[\"language\"]}):')\n    print(response['answer'])\n    print('-' * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:25:33.238802Z","iopub.execute_input":"2026-02-19T12:25:33.239305Z","iopub.status.idle":"2026-02-19T12:26:35.405980Z","shell.execute_reply.started":"2026-02-19T12:25:33.239247Z","shell.execute_reply":"2026-02-19T12:26:35.405091Z"}},"outputs":[{"name":"stdout","text":"============================================================\nЁЯТм AI Tutor тАФ Simulated Conversation\n============================================================\n\nЁЯСж Student: ржЖржорж╛ржХрзЗ ржмржирзНржзрзБрждрзНржм рж╕ржорзНржкрж░рзНржХрзЗ ржмрж▓рзЛред\nЁЯдЦ AI Tutor (chat | bengali):\nрж░рж╛рж╢рзЗржж ржмрж▓рж▓!\n------------------------------------------------------------\n\nЁЯСж Student: ржмржирзНржзрзБрждрзНржм ржирж┐ржпрж╝рзЗ ржХрзБржЗржЬ ржжрж╛ржУред\nЁЯдЦ AI Tutor (quiz | bengali):\n{\n  \"questions\": [\n    {\n      \"question\": \"ржПржмрж╛рж░ ржПржХржЯрж╛ ржЫржХ ржЖржБржХрж┐рждрзЗ ржирж┐ржЬрзЗрж░ ржнрж╛рж▓рзЛ рж▓рж╛ржЧрж╛рж░ ржХржерж╛ рж▓рж┐я┐╜riz ржХрж░рзЗржи, рждрзБржорж┐ ржХрзА ржХрж░ржмрзЗ?\\nA) ржЦрзБржм ржнрж╛рж▓рзЛ рж▓рж╛ржЧрж▓ рж░рж╛рж╢рзЗржж gрз▒\\nB) ржШрзБрж░ ржкрж╛ржа ржкрж░рзЗ\\nC) ржмрзНржпрж╛ржЩрзЗрж░ рж╕рж╛ржЬрж╛\\nD) ржкрзГрж╖рзНржарж╛ 35\\n\" ,\n      \"options\": [\"A) ржЦрзБржм ржнрж╛рж▓рзЛ рж▓рж╛ржЧрж▓ рж░рж╛рж╢рзЗржж gрз▒\", \"B) ржШрзБрж░ ржкрж╛ржа ржкрж░рзЗ\", \"C) ржмрзНржпрж╛ржЩрзЗрж░ рж╕рж╛ржЬрж╛\", \"D) ржкрзГрж╖рзНржарж╛ 35\"],\n      \"correct\": \"A\",\n      \"explanation\": \"ржПржмрж╛рж░ ржПржХржЯрж╛ ржЫржХ ржЖржБржХрж┐рждрзЗ ржирж┐ржЬрзЗрж░ ржнрж╛рж▓рзЛ рж▓рж╛ржЧрж╛рж░ ржХржерж╛ рж▓рж┐ржбрзЗржи рж╕ржорж╕рзНрждрж┐рждрж┐рждрзЗ, ржЙрждрзНрж╛рж░рж╛ ржЦрзБржм ржнрж╛рж▓рзЛ рж▓рж╛ржЧрж▓ рж░рж╛рж╢рзЗржж gрз▒ рж╣ржмрзЗ, ржпрж╛ рж╢рзБржирзНржп ржХрж░рзЗржи ржПрж░ рж╕ржоржпрж╝рзЗрж░ рж╕ржорж╛ржирзНржпрждрж╛ржЯрж┐.\"\n    },\n    {\n      \"question\": \"рж░рж╛рж╢рзЗржж ржмрж▓рж▓рзЗржи 'ржирзЛржорж╛ржи' ржХрзА?\\nA)\n------------------------------------------------------------\n\nЁЯСж Student: Tell me about family.\nЁЯдЦ AI Tutor (chat | english):\nрж░рж╛рж╢рзЗржж ржЧрж╛ржЫржЯрж┐рж░ рж╕ржорзНржкржирзНржирждрж╛рж░ рж╕ржорж╛ржи:\n\nрж░рж╛рж╢рзЗржж ржкрж╛рж░ржмрзЗ рждрзЛ:\n\nржЬрж┐ржЬрзНя┐╜ Jaipur (рдЬрдпрдкреБрд░) - рдмрд┐рд╣рд╛рд░реА рдХреА рджреЗрд╢рднрд╛рдЧреА рдорд╣реЛрддреНрд╕рд╡\n\nJaipur, also known as the Pink City of India due to the color of the buildings in its old city center, is a prominent cultural and historical hub located in Rajasthan state within India's vast tapestry of states rich with heritage. It stands out not only for its vibrant past but also because it hosts numerous festivals that reflect both regional traditions and national pride throughout the year. Here are some key points highlighting how Jaipur contributes significantly during various times through celebrations like Diwali, Holi, Jalwa-Tika, Gangaur, Teej Festival, etc.:\n\n1. **Diwali** or Deepavali тАУ The festival symbolizes triumph over darkness by light; this time sees families gather at temples across Jaipur where they offer prayers seeking blessings from deities while enjoying fireworks displays illuminating the night sky against red sandstone walls. Residents adorn their homes bright\n------------------------------------------------------------\n","output_type":"stream"}],"execution_count":21},{"id":"step9-md","cell_type":"markdown","source":"## Step 9: Performance Summary","metadata":{}},{"id":"perf-summary","cell_type":"code","source":"import time\n\n# Speed test\ntest_q = 'ржкрж░рж┐ржмрж╛рж░ ржХрзА?'\nstart = time.time()\nans, _ = generate_answer(test_q, mode='chat')\nelapsed = time.time() - start\n\nprint('=' * 60)\nprint('ЁЯУК Performance Summary')\nprint('=' * 60)\nprint(f'''\nЁЯза Model       : Phi-3 Mini 4k (4-bit quantized)\nЁЯУЪ Knowledge   : NCTB Class 3 Bengali (107 pages, 190 chunks)\nЁЯФН Retrieval   : FAISS + Multilingual MiniLM\nтЪб Speed        : {elapsed:.1f}s per response\nЁЯМР Languages   : Bengali + English\nЁЯУЭ Modes       : Chat, Quiz, Explain\n\nтЬЕ Ready for:\n   тЖТ Whisper STT integration (voice input)\n   тЖТ Edge-TTS integration (voice output)\n   тЖТ Django REST API wrapping\n   тЖТ Flutter app connection\n''')\nprint('=' * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:26:35.407233Z","iopub.execute_input":"2026-02-19T12:26:35.407487Z","iopub.status.idle":"2026-02-19T12:26:42.923857Z","shell.execute_reply.started":"2026-02-19T12:26:35.407462Z","shell.execute_reply":"2026-02-19T12:26:42.922912Z"}},"outputs":[{"name":"stdout","text":"============================================================\nЁЯУК Performance Summary\n============================================================\n\nЁЯза Model       : Phi-3 Mini 4k (4-bit quantized)\nЁЯУЪ Knowledge   : NCTB Class 3 Bengali (107 pages, 190 chunks)\nЁЯФН Retrieval   : FAISS + Multilingual MiniLM\nтЪб Speed        : 7.5s per response\nЁЯМР Languages   : Bengali + English\nЁЯУЭ Modes       : Chat, Quiz, Explain\n\nтЬЕ Ready for:\n   тЖТ Whisper STT integration (voice input)\n   тЖТ Edge-TTS integration (voice output)\n   тЖТ Django REST API wrapping\n   тЖТ Flutter app connection\n\n============================================================\n","output_type":"stream"}],"execution_count":22}]}